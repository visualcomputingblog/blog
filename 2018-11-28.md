## 【论文阅读】利用线性冗余训练小网络（ExpandNets: Exploiting Linear Redundancy to Train Small Networks）

### Contribution
这是一篇挺有意思的论文，论文提出了一种新的训练方法来提高小网络的精度。知识迁移用大网络指导小网络训练是现在比较流行的提高小网络精度的方法，论文从参数冗余有助于学习的角度考虑给出另外一种解决方案，具体做法就是将一个线性层扩展成多个线性层得到一个扩展后的网络，训练好之后的扩展网络可以压缩回小网络，实验表明扩展网络的精度明显优于直接训练小网络。进一步的，论文运用知识迁移方法可以进一步提高网络性能。总体而言，论文创新点在于如下几个方面：

- 简单的策略对小网络引入冗余，提高网络学习性能，并且在数学上引入的冗余可以压缩回去。
- 论文提出了一种有效的网络初始化方法初始化扩展网络。

### Methods
